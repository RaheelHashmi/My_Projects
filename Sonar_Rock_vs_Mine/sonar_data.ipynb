{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226c825c-80cf-4aab-b9e2-46833d982937",
   "metadata": {},
   "source": [
    "# **SONAR** <h3> *Rock* **vs** *Mine* </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2437b6-829a-4457-bb98-b09158ecfabd",
   "metadata": {},
   "source": [
    "[![Submarine_vs_Minefield](./submarine_vs_minefield.jpg \"3d illustration of a submarine passing through a minefield\")](https://media.istockphoto.com/id/932625038/photo/3d-illustration-of-a-submarine-passing-through-a-minefield.jpg?s=612x612&w=0&k=20&c=WyPyf29iGu3V1_VMCVI5u0WHurX1Dxy04YCht6bXc98=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909a375-fabd-47c6-bdb9-8f1b655fd05a",
   "metadata": {},
   "source": [
    "## Objective :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada172bf-75c5-41a1-9f69-dfe5410578ff",
   "metadata": {},
   "source": [
    "In this project, we are trying to build a system to predict whether the object beneath the submarine is a **Mine** or a **Rock**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037a965-3ab2-48e9-8f0b-8c10a46bcc4a",
   "metadata": {},
   "source": [
    "First, let's import all the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938c9807-dc39-409a-b352-7f2153ad7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09761c07-e59d-4f9c-a703-bef79def0e89",
   "metadata": {},
   "source": [
    "Now, we shall read the csv data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f39b1-e146-4264-9398-1f0b2fe6d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data = pd.read_csv(\"sonar_data.csv\", header=None)\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cd791-da4b-486a-bf99-4c76da8cf169",
   "metadata": {},
   "source": [
    "Let's explore our dataset in more detail before we proceed to the model building phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df192f6a-e84d-4f10-9511-4e9693fc6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216e5f04-7937-493e-8590-22b6cde4ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sonar_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31473ab-718b-458b-a46d-6625be1ea0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data[60].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880ce03-cb8f-42d4-83db-3b1e5044188e",
   "metadata": {},
   "source": [
    "We saw that our dataset doesn't contain any null values and all the feature columns are in the float64 format (in the *sonar_data.info()* command). Also, the classes are fairly balanced for the label column 60 (**M:** 111, **R:** 97). \n",
    "So, now we're ready to build a model to identify between a rock and a mine.\n",
    "First, let's define our feature variables and our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6924bf-7cbc-4578-a849-15421a9a4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sonar_data.drop(60, axis=1)\n",
    "y = sonar_data[60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657cbec0-9c24-4403-9c9d-0e3ada020a25",
   "metadata": {},
   "source": [
    "Next, we split our dataset to a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e274527-d55b-4c35-9717-23ff33bbfc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: X_train(187, 60) \t y_train(187,)\n",
      "Shape of the testing data: X_test(21, 60) \t y_train(21,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=0)\n",
    "print(f\"Shape of the training data: X_train{X_train.shape} \\t y_train{y_train.shape}\")\n",
    "print(f\"Shape of the testing data: X_test{X_test.shape} \\t y_train{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d46dc8-0c96-4c61-9aee-0e34e25043ff",
   "metadata": {},
   "source": [
    "Now, let's create our model object. We're using the **Logistic Regression** model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd0d6df-0ab1-4e36-bf87-2b336d57fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42ef59-34e1-419f-8a10-8741ff151e05",
   "metadata": {},
   "source": [
    "We'll perform a Grid Search to find the optimum value for our hyperparameters. First, we'll create a params dictionary containing all the combinations of the hyperparameters from which we want grid search to find the optimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8505dd-8d12-4147-a3f4-27a748c21b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\"solver\": [\"lbfgs\", \"sag\", \"newton-cg\", \"newton-cholesky\", \"liblinear\", \"saga\"], \"penalty\": [\"l2\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "          {\"solver\": [\"lbfgs\", \"sag\", \"newton-cg\", \"newton-cholesky\", \"saga\"], \"penalty\": [\"none\"]},\n",
    "          {\"solver\": [\"liblinear\", \"saga\"], \"penalty\": [\"l1\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "          {\"solver\": [\"saga\"], \"penalty\": [\"elasticnet\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"l1_ratio\": np.linspace(0, 1, 101)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6ef4d-1067-413f-aebb-6319a5cb7161",
   "metadata": {},
   "source": [
    "Now, we give the params dictionary as a parameter to the **GridSearchCV()** and do a 20-fold Stratified K-Fold cross validation to find the optimum value for hyperparameters for our logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cf048-3b2c-4712-a7fb-789dd47e77f7",
   "metadata": {},
   "source": [
    "*(__Note:__ Running the following cell could take a long time, as we are  training and testing up to 15360 models in this step).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5bf356-1326-4776-b4b4-995e44006754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=20, estimator=LogisticRegression(max_iter=10000), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                     &#x27;newton-cholesky&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "                         {&#x27;penalty&#x27;: [&#x27;none&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                     &#x27;newton-cholesky&#x27;, &#x27;saga&#x27;]},\n",
       "                         {&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;],...\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  ]),\n",
       "                          &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;], &#x27;solver&#x27;: [&#x27;saga&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=20, estimator=LogisticRegression(max_iter=10000), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                     &#x27;newton-cholesky&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "                         {&#x27;penalty&#x27;: [&#x27;none&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                     &#x27;newton-cholesky&#x27;, &#x27;saga&#x27;]},\n",
       "                         {&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;],...\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  ]),\n",
       "                          &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;], &#x27;solver&#x27;: [&#x27;saga&#x27;]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=20, estimator=LogisticRegression(max_iter=10000), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'penalty': ['l2'],\n",
       "                          'solver': ['lbfgs', 'sag', 'newton-cg',\n",
       "                                     'newton-cholesky', 'liblinear', 'saga']},\n",
       "                         {'penalty': ['none'],\n",
       "                          'solver': ['lbfgs', 'sag', 'newton-cg',\n",
       "                                     'newton-cholesky', 'saga']},\n",
       "                         {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'penalty': ['l1'],...\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  ]),\n",
       "                          'penalty': ['elasticnet'], 'solver': ['saga']}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid1 = GridSearchCV(lr, param_grid=params, cv=20, n_jobs=-1)\n",
    "Grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dfa46b-b895-4e86-9351-1aa7b6782c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, l1_ratio=0.96, max_iter=10000, penalty=&#x27;elasticnet&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, l1_ratio=0.96, max_iter=10000, penalty=&#x27;elasticnet&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, l1_ratio=0.96, max_iter=10000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357e2f64-2c5c-4230-991f-322f28869e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927777777777779"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aae5c0-e8c9-47e1-a3fe-959eaba109bf",
   "metadata": {},
   "source": [
    "We can see the best values for accuracy are derived using the parameters: **C**=10, **l1_ratio**=0.96, **max_iter**=10000, **penalty**=\"elasticnet\", **solver**=\"saga\". Now just for curiosity's sake, let's see the other top performing hyperparameters values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6ab8ed-71b0-4e1b-9746-10a3f6540087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.497140</td>\n",
       "      <td>0.065158</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>10</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.96</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.96, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.545480</td>\n",
       "      <td>0.084131</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>10</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.97</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.97, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.376358</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>10</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.9, 'penalty': 'elastic...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.418338</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>10</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.91</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.91, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.126992</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "561       0.497140      0.065158         0.002344        0.005581      10   \n",
       "562       0.545480      0.084131         0.006502        0.007530      10   \n",
       "555       0.376358      0.030006         0.004888        0.007083      10   \n",
       "556       0.418338      0.039640         0.004076        0.006196      10   \n",
       "28        0.010500      0.003722         0.005450        0.001464      10   \n",
       "\n",
       "    param_penalty param_solver param_l1_ratio  \\\n",
       "561    elasticnet         saga           0.96   \n",
       "562    elasticnet         saga           0.97   \n",
       "555    elasticnet         saga            0.9   \n",
       "556    elasticnet         saga           0.91   \n",
       "28             l2    liblinear            NaN   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "561  {'C': 10, 'l1_ratio': 0.96, 'penalty': 'elasti...                0.9   \n",
       "562  {'C': 10, 'l1_ratio': 0.97, 'penalty': 'elasti...                0.9   \n",
       "555  {'C': 10, 'l1_ratio': 0.9, 'penalty': 'elastic...                0.9   \n",
       "556  {'C': 10, 'l1_ratio': 0.91, 'penalty': 'elasti...                0.9   \n",
       "28   {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}                0.9   \n",
       "\n",
       "     ...  split13_test_score  split14_test_score  split15_test_score  \\\n",
       "561  ...            0.666667            0.777778            0.777778   \n",
       "562  ...            0.666667            0.777778            0.777778   \n",
       "555  ...            0.777778            0.777778            0.777778   \n",
       "556  ...            0.777778            0.777778            0.777778   \n",
       "28   ...            0.777778            0.666667            0.888889   \n",
       "\n",
       "     split16_test_score  split17_test_score  split18_test_score  \\\n",
       "561            0.888889            0.777778            0.888889   \n",
       "562            0.888889            0.777778            0.888889   \n",
       "555            0.888889            0.666667            0.888889   \n",
       "556            0.888889            0.666667            0.888889   \n",
       "28             0.888889            0.666667            1.000000   \n",
       "\n",
       "     split19_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "561            0.777778         0.792778        0.135504                1  \n",
       "562            0.777778         0.792778        0.135504                1  \n",
       "555            0.777778         0.792778        0.135504                3  \n",
       "556            0.777778         0.792778        0.135504                3  \n",
       "28             0.555556         0.792778        0.126992                5  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(Grid1.cv_results_)\n",
    "top100 = results_df.sort_values(by=\"rank_test_score\").head(100)\n",
    "top100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fd29f-3279-44d5-803c-61776214dda4",
   "metadata": {},
   "source": [
    "Using the best hyperparameter values, let's train the model again and see how well it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712fb283-8561-410c-b491-2992cc4cc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Grid1.best_estimator_\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd832416-8c18-43da-b115-e10b4d8f9d3c",
   "metadata": {},
   "source": [
    "## Evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c4fb981-7a27-498b-9763-1749557904cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on the test set:\", accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b2865-9c46-476d-8782-debc83e484a3",
   "metadata": {},
   "source": [
    "As we see, our model got a score of around 76.19% on the test dataset. Now, let's create a confusion matrix to get a better sense of the performance of our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71321ef-5c24-4b88-948c-e2d8a42a4548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_hat, labels=lr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878f740-e030-410d-92bf-81801f0e1f05",
   "metadata": {},
   "source": [
    "The above confusion matrix tells us that out of the 11 mines in the test data, our model successfully identified 10 of them and it wrongly predicted one of the mine as a rock. And out of the 10 rocks in the test data, our model successfully identified 6 of them and erroneously predicted 4 of the rocks as mines. Now, let's expand on this with a classification report on the performance of our model on the test data and see the score of our model for key evaluation metrics: **Precision**, **Recall** and **F1-score** for both mine and rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50048d63-a705-4190-a8c5-0892831a325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.71      0.91      0.80        11\n",
      "           R       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.79      0.75      0.75        21\n",
      "weighted avg       0.78      0.76      0.76        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b783893-b2d2-458b-a1ba-77032b035315",
   "metadata": {},
   "source": [
    "Looking at the classification report above, the first column for **Precision** tells us that when our model outputs it's prediction as a rock, it's usually correct more times than when it outputs a prediction as a mine (**6 out of 7=0.86** *vs* **10 out of 14=0.71**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352a981-ad53-468b-a0c2-e5a9e8b4a450",
   "metadata": {},
   "source": [
    "But when it's actually a mine, the **Recall** column tells us that our model does a better job at identifying it as a mine than correctly identifying a rock when it's actually a rock (**10 out of 11=0.91** *vs* **6 out of 10=0.60**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d70d3-2175-420a-aa39-2721559fce54",
   "metadata": {},
   "source": [
    "The third column for **F1-score** is the harmonic mean of the first two columns and gives us a better sense of our model's performance by balancing both precision and recall. It tells us that overall our model is slightly better at predicting mines than rocks (**0.80** *vs* **0.71**). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd1d3f-4a90-43ac-a1f6-e36abb8a027f",
   "metadata": {},
   "source": [
    "That's all from me for this project. Thank you for your time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
