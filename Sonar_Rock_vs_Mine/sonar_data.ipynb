{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226c825c-80cf-4aab-b9e2-46833d982937",
   "metadata": {},
   "source": [
    "# **SONAR** <h3> *Rock* **vs** *Mine* </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2437b6-829a-4457-bb98-b09158ecfabd",
   "metadata": {},
   "source": [
    "[![Submarine_vs_Minefield](./submarine_vs_minefield.jpg \"3d illustration of a submarine passing through a minefield\")](https://media.istockphoto.com/id/932625038/photo/3d-illustration-of-a-submarine-passing-through-a-minefield.jpg?s=612x612&w=0&k=20&c=WyPyf29iGu3V1_VMCVI5u0WHurX1Dxy04YCht6bXc98=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909a375-fabd-47c6-bdb9-8f1b655fd05a",
   "metadata": {},
   "source": [
    "## Objective :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada172bf-75c5-41a1-9f69-dfe5410578ff",
   "metadata": {},
   "source": [
    "In this project, we are trying to build a system to predict whether the object beneath the submarine is mine or rock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037a965-3ab2-48e9-8f0b-8c10a46bcc4a",
   "metadata": {},
   "source": [
    "First, let's import all the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938c9807-dc39-409a-b352-7f2153ad7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09761c07-e59d-4f9c-a703-bef79def0e89",
   "metadata": {},
   "source": [
    "Now, we shall read the csv data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f39b1-e146-4264-9398-1f0b2fe6d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data = pd.read_csv(\"sonar_data.csv\", header=None)\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cd791-da4b-486a-bf99-4c76da8cf169",
   "metadata": {},
   "source": [
    "Let's try to understand our dataset better before we go into the model building stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df192f6a-e84d-4f10-9511-4e9693fc6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216e5f04-7937-493e-8590-22b6cde4ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sonar_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31473ab-718b-458b-a46d-6625be1ea0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data[60].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880ce03-cb8f-42d4-83db-3b1e5044188e",
   "metadata": {},
   "source": [
    "We saw the data doesn't contain any null values(in the *sonar_data.info()* command). Also, the classes are fairly balanced for the label column 60.(**M:** 111, **R:** 97) \n",
    "So, now we're ready to build a model to identify between a rock and a mine.\n",
    "First, let's define our feature variables and our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6924bf-7cbc-4578-a849-15421a9a4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sonar_data.drop(60, axis=1)\n",
    "y = sonar_data[60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657cbec0-9c24-4403-9c9d-0e3ada020a25",
   "metadata": {},
   "source": [
    "Now, we split our dataset to train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e274527-d55b-4c35-9717-23ff33bbfc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: X_train(187, 60) \t y_train(187,)\n",
      "Shape of the testing data: X_test(21, 60) \t y_train(21,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=0)\n",
    "print(f\"Shape of the training data: X_train{X_train.shape} \\t y_train{y_train.shape}\")\n",
    "print(f\"Shape of the testing data: X_test{X_test.shape} \\t y_train{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d46dc8-0c96-4c61-9aee-0e34e25043ff",
   "metadata": {},
   "source": [
    "Now, let's create our model object. We're using **Logistic Regression** model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd0d6df-0ab1-4e36-bf87-2b336d57fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42ef59-34e1-419f-8a10-8741ff151e05",
   "metadata": {},
   "source": [
    "We'll perform a Grid Search to find the optimum value for our hyperparameters. First, we'll create a params dictionary containing all the combinations of the hyperparameters from which we want grid search to find the optimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8505dd-8d12-4147-a3f4-27a748c21b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\"solver\": [\"lbfgs\", \"sag\", \"newton-cg\", \"liblinear\", \"saga\"], \"penalty\": [\"l2\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "          {\"solver\": [\"lbfgs\", \"sag\", \"newton-cg\", \"saga\"], \"penalty\": [\"none\"]},\n",
    "          {\"solver\": [\"liblinear\", \"saga\"], \"penalty\": [\"l1\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "          {\"solver\": [\"saga\"], \"penalty\": [\"elasticnet\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"l1_ratio\": list(np.linspace(0, 1, 101))}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6ef4d-1067-413f-aebb-6319a5cb7161",
   "metadata": {},
   "source": [
    "Now, we give the params dictionary as a parameter to the **GridSearchCV()** and do a 20-fold Stratified K-Fold cross validation to find the optimum value for hyperparameters for our logistic regression model. We'll also use **tqdm()** from the tqdm library to keep a track of the progress via a progress bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cf048-3b2c-4712-a7fb-789dd47e77f7",
   "metadata": {},
   "source": [
    "*(__Note:__ Running the following cell could take a long time, as we are  training and testing upto 15200 models in this step).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5bf356-1326-4776-b4b4-995e44006754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [44:03<00:00, 660.83s/it]\n"
     ]
    }
   ],
   "source": [
    "Grid1 = GridSearchCV(lr, param_grid=params, cv=20, n_jobs=-1)\n",
    "for param in tqdm(Grid1.param_grid):\n",
    "    Grid1.set_params(param_grid=param)\n",
    "    Grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dfa46b-b895-4e86-9351-1aa7b6782c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, l1_ratio=0.96, max_iter=10000, penalty='elasticnet',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357e2f64-2c5c-4230-991f-322f28869e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927777777777779"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aae5c0-e8c9-47e1-a3fe-959eaba109bf",
   "metadata": {},
   "source": [
    "We can see the best values for accuracy are derived using the parameters: **C**=10, **l1_ratio**=0.96, **max_iter**=10000, **penalty**='elasticnet', **solver**='saga'. Now just for curiosity purpose, let's see the other top performing hyperparameters values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6ab8ed-71b0-4e1b-9746-10a3f6540087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.698576</td>\n",
       "      <td>0.113957</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.97, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.617790</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.96, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.042098</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.9, 'penalty': 'elastic...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.639674</td>\n",
       "      <td>0.113321</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.91, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.135504</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.728843</td>\n",
       "      <td>0.128334</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'l1_ratio': 0.98, 'penalty': 'elasti...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.787778</td>\n",
       "      <td>0.144098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "501       0.698576      0.113957         0.002843        0.005606      10   \n",
       "500       0.617790      0.088994         0.003907        0.006766      10   \n",
       "494       0.517007      0.042098         0.001763        0.004702      10   \n",
       "495       0.639674      0.113321         0.005571        0.006380      10   \n",
       "502       0.728843      0.128334         0.004757        0.007272      10   \n",
       "\n",
       "    param_l1_ratio param_penalty param_solver  \\\n",
       "501           0.97    elasticnet         saga   \n",
       "500           0.96    elasticnet         saga   \n",
       "494            0.9    elasticnet         saga   \n",
       "495           0.91    elasticnet         saga   \n",
       "502           0.98    elasticnet         saga   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "501  {'C': 10, 'l1_ratio': 0.97, 'penalty': 'elasti...                0.9   \n",
       "500  {'C': 10, 'l1_ratio': 0.96, 'penalty': 'elasti...                0.9   \n",
       "494  {'C': 10, 'l1_ratio': 0.9, 'penalty': 'elastic...                0.9   \n",
       "495  {'C': 10, 'l1_ratio': 0.91, 'penalty': 'elasti...                0.9   \n",
       "502  {'C': 10, 'l1_ratio': 0.98, 'penalty': 'elasti...                0.9   \n",
       "\n",
       "     ...  split13_test_score  split14_test_score  split15_test_score  \\\n",
       "501  ...            0.666667            0.777778            0.777778   \n",
       "500  ...            0.666667            0.777778            0.777778   \n",
       "494  ...            0.777778            0.777778            0.777778   \n",
       "495  ...            0.777778            0.777778            0.777778   \n",
       "502  ...            0.666667            0.777778            0.777778   \n",
       "\n",
       "     split16_test_score  split17_test_score  split18_test_score  \\\n",
       "501            0.888889            0.777778            0.888889   \n",
       "500            0.888889            0.777778            0.888889   \n",
       "494            0.888889            0.666667            0.888889   \n",
       "495            0.888889            0.666667            0.888889   \n",
       "502            0.888889            0.777778            0.888889   \n",
       "\n",
       "     split19_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "501            0.777778         0.792778        0.135504                1  \n",
       "500            0.777778         0.792778        0.135504                1  \n",
       "494            0.777778         0.792778        0.135504                3  \n",
       "495            0.777778         0.792778        0.135504                3  \n",
       "502            0.777778         0.787778        0.144098                5  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(Grid1.cv_results_)\n",
    "top100 = results_df.sort_values(by=\"rank_test_score\").head(100)\n",
    "top100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fd29f-3279-44d5-803c-61776214dda4",
   "metadata": {},
   "source": [
    "Using the best hyperparameter values, let's train the model again and see how well it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712fb283-8561-410c-b491-2992cc4cc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Grid1.best_estimator_\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd832416-8c18-43da-b115-e10b4d8f9d3c",
   "metadata": {},
   "source": [
    "## Evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c4fb981-7a27-498b-9763-1749557904cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on the test set:\", accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b2865-9c46-476d-8782-debc83e484a3",
   "metadata": {},
   "source": [
    "As we see our model got a score of around 76.19% on the test dataset. Now, let's create a confusion matrix to get a better sense of the performance of our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71321ef-5c24-4b88-948c-e2d8a42a4548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_hat, labels=lr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878f740-e030-410d-92bf-81801f0e1f05",
   "metadata": {},
   "source": [
    "The above confusion matrix tells us that out of the 11 mines in the test data, our model successfully identified 10 of them and it wrongly predicted one of the mine as a rock. And out of the 10 rocks in the test data, our model successfully identified 6 of them and erroneously predicted 4 of the rocks as mine. Now, let's expand on this with a classification report on the performance of our model on the test data and see the score of our model for key evaluation metrics: **Precision**, **Recall** and **F1-score** for both mine and rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50048d63-a705-4190-a8c5-0892831a325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.71      0.91      0.80        11\n",
      "           R       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.79      0.75      0.75        21\n",
      "weighted avg       0.78      0.76      0.76        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b783893-b2d2-458b-a1ba-77032b035315",
   "metadata": {},
   "source": [
    "Looking at the classification report above, the first column for **Precision** tells us that when our model outputs it's prediction as a rock, it's usually correct more times than when it outputs a prediction as a mine (**6 out of 7=0.86** *vs* **10 out of 14=0.71**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352a981-ad53-468b-a0c2-e5a9e8b4a450",
   "metadata": {},
   "source": [
    "But when it's actually a mine, the **Recall** column tells us that our model does a better job at identifying it as a mine than correctly identifying a rock when it's actually a rock (**10 out of 11=0.91** *vs* **6 out of 10=0.60**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d70d3-2175-420a-aa39-2721559fce54",
   "metadata": {},
   "source": [
    "The third column for **F1-score** is the harmonic mean of the first two columns and gives us a better sense of our model's performance by balancing both precision and recall. It tells us that overall our model is slightly better at predicting mines than rocks (**0.80** *vs* **0.71**). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd1d3f-4a90-43ac-a1f6-e36abb8a027f",
   "metadata": {},
   "source": [
    "That's all from me for this project. Thank you for your time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
